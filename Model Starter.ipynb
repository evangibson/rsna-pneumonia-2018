{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Test\n",
    "Before we move onto tweaking and tuning models, we should ensure that our hardware is working as anticipated.\n",
    "\n",
    "One of the major turnoffs to machine learning on vast data is the amount of time it can take to train. Using your device's GPU can significantly reduce image processing time and greatly reduce headaches (and the temperature of your CPU).\n",
    "\n",
    "For this exercise, I encourage using a smaller portion of the project data. However, if you're confident using [TensorFlow](https://www.tensorflow.org/), you might as well go for all of it. As you might've guessed, TensorFlow isn't the easiest Python library to manage. You'll need more than a simple `pip install tensorflow` to get it running.\n",
    "\n",
    "Here is an exceptionally helpful [tutorial](https://towardsdatascience.com/installing-tensorflow-with-cuda-cudnn-and-gpu-support-on-windows-10-60693e46e781) to get you started. It's tailored to Windows 10 and NVIDIA, but it should give you a good starting point even if you don't use that setup.\n",
    "\n",
    "The setup might be painful, but I promise it's worth it. The cell below contains code that, when run, list out all of the devices that TensorFlow is using. On most setups, a CPU and GPU should appear (depending on your hardware)\n",
    "\n",
    "\n",
    "#### Notebook Goals\n",
    "- Enable TensorFlow to work on your machine as optimally as possible.\n",
    "- Test the pathing schema of our training data.\n",
    "- Run this notebook from top to bottom, ensuring no errors exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The output shows the list of devices you're using. For me, that's my CPU and two default GPUs, as shown.\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` \n",
    "name: \"/cpu:0\" device_type: \"CPU\" memory_limit: 268435456 locality { } incarnation: 4402277519343584096,\n",
    "\n",
    "name: \"/gpu:0\" device_type: \"GPU\" memory_limit: 6772842168 locality { bus_id: 1 } incarnation: 7471795903849088328 physical_device_desc: \"device: 0, name: GeForce RTX 2080ti, pci bus id: 0000:05:00.0\"\n",
    "\n",
    "name: \"/gpu:1\" device_type: \"GPU\" memory_limit: 6772842168 locality { bus_id: 2 } incarnation: 74717959038490889912 physical_device_desc: \"device: 0, name: GeForce RTX 2070, pci bus id: 0000:05:00.0\"\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your output will be different from mine. Ensure you have a GPU available (if you have one) before moving onto the next cells.\n",
    "\n",
    "\n",
    "#### Staging your data\n",
    "The code block below deals with staging our data for processing and class definitions. If you compare this to many \"tutorial\" versions of tensorflow modelling, you'll find that this method is much easier on your computer's hardware. Why?\n",
    "\n",
    "*Don't worry about the processing procedures too much; this notebook is meant to tell us if TensorFlow is working properly for you. We'll tune this later.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# You can point this to one folder above your class-defined folders\n",
    "train_folder = 'path\\\\to\\\\train\\\\'\n",
    "val_folder = 'path\\\\to\\\\valid\\\\'\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# This method depends on our folder schema that we established in earlier phases of the project\n",
    "train_generator = train_datagen.flow_from_directory(train_folder,\n",
    "                                                    color_mode='grayscale',\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(val_folder,\n",
    "                                                        color_mode='grayscale',\n",
    "                                                        batch_size=batch_size,\n",
    "                                                        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing your model\n",
    "The model below is far from optimized. Again, this notebook is only supposed to tell us if your setup is working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=3, activation='relu', padding='same', input_shape=(256, 256, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "#Flatten the model and prepare for output\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3, activation='softmax')) #softmax works for categorical\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training your model\n",
    "The following might take a whole to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(train_generator,\n",
    "                              steps_per_epoch=20548 // batch_size,\n",
    "                              epochs=2,\n",
    "                              verbose=1,\n",
    "                              validation_data=validation_generator,\n",
    "                              validation_steps=5136 // batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Congratulations! You should be ready to make this model more complex now."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
